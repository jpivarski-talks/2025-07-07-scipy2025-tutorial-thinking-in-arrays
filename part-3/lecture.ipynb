{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "882b9184",
   "metadata": {},
   "source": [
    "# Part 3: JIT-compilation with Numba and JAX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6fdc85",
   "metadata": {},
   "source": [
    "In lecture 2 you've seen that fusing operations is powerful and crucial for performance!\n",
    "\n",
    "Essentially, we're able to get rid of _intermediate_ arrays by \"fusing operations\" using just-in-time (JIT) compilation by applying these operations in a _single_ iteration over our data.\n",
    "\n",
    "Fusing operations is a tricky task however. There are a few ways to achieve this for array processing in Python, and I'd like to highlight two of them:\n",
    "\n",
    "- Numba: https://numba.pydata.org\n",
    "- JAX: https://github.com/jax-ml/jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf9914c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy\n",
    "import numpy as np\n",
    "\n",
    "# JAX\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "jax.config.update(\"jax_platform_name\", \"cpu\")\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "# Numba\n",
    "import numba as nb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070a37b3",
   "metadata": {},
   "source": [
    "Let's consider the quadratic formula example again, and compare the runtimes for NumPy, Numba, and JAX:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da6227aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup data\n",
    "a = np.random.uniform(5, 10, 5_000_000)\n",
    "b = np.random.uniform(10, 20, 5_000_000)\n",
    "c = np.random.uniform(-0.1, 0.1, 5_000_000)\n",
    "\n",
    "\n",
    "# Setup quadratic formula\n",
    "def quadratic_formula(a, b, c):\n",
    "    return (-b + np.sqrt(b**2 - 4*a*c)) / (2*a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335e56fd",
   "metadata": {},
   "source": [
    "NumPy case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ab610b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.3 ms ± 1.82 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r3\n",
    "\n",
    "quadratic_formula(a, b, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281d0563",
   "metadata": {},
   "source": [
    "Numba case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efdebf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.njit  # JIT compile!\n",
    "def quadratic_formula_numba(a, b, c):\n",
    "    n = a.shape[0]\n",
    "    out = np.empty(n)\n",
    "    for i in range(n):\n",
    "        out[i] = (-b[i] + np.sqrt(b[i]**2 - 4*a[i]*c[i])) / (2*a[i])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec9a0b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 94.57 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "81.6 ms ± 184 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1\n",
    "\n",
    "quadratic_formula_numba(a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd7f5b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.86 ms ± 474 μs per loop (mean ± std. dev. of 3 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n10 -r3\n",
    "\n",
    "quadratic_formula_numba(a, b, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b672a8",
   "metadata": {},
   "source": [
    "JAX case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1dc6562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup data\n",
    "a_jax = jnp.asarray(a)\n",
    "b_jax = jnp.asarray(b)\n",
    "c_jax = jnp.asarray(c)\n",
    "\n",
    "\n",
    "@jax.jit  # JIT compile!\n",
    "def quadratic_formula_jax(a, b, c):\n",
    "    return (-b + jnp.sqrt(b**2 - 4*a*c)) / (2*a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b550bc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 19.43 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "7.8 ms ± 13.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1\n",
    "\n",
    "quadratic_formula_jax(a_jax, b_jax, c_jax).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "410130fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.24 ms ± 23.4 μs per loop (mean ± std. dev. of 3 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n10 -r3\n",
    "\n",
    "quadratic_formula_jax(a_jax, b_jax, c_jax).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d047444",
   "metadata": {},
   "source": [
    "The first invocation for JAX & Numba took longer than consecutive ones. That's the compile time! Afterwards the compiled function is cached...\n",
    "\n",
    "But JAX is still much faster, why?\n",
    "\n",
    "One important difference is that JAX uses as many threads as it has access to. Numba is single-threaded, but can be multithreaded using `parallel=True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de06e2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.njit(parallel=True)  # JIT compile with `parallel=True`!\n",
    "def quadratic_formula_numba_parallel(a, b, c):\n",
    "    n = a.shape[0]\n",
    "    out = np.empty(n)\n",
    "    for i in nb.prange(n):  # note: `range` -> `nb.prange`\n",
    "        out[i] = (-b[i] + np.sqrt(b[i]**2 - 4*a[i]*c[i])) / (2*a[i])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7f4681e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 90.82 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "25.5 ms ± 57.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1\n",
    "\n",
    "quadratic_formula_numba_parallel(a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3529e39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.98 ms ± 31.1 μs per loop (mean ± std. dev. of 3 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n10 -r3\n",
    "\n",
    "quadratic_formula_numba_parallel(a, b, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21a60ef",
   "metadata": {},
   "source": [
    "Now we're roughly on-par with JAX and Numba with ~2-3ms runtime compared to NumPy's ~23ms.\n",
    "\n",
    "\n",
    "You might have noticed a fundamental difference between JAX and Numba in how those kernels are written: \n",
    "\n",
    "- Numba forces[<sup id=\"fn1-back\">1</sup>](#fn1) you to write _imperative_ code\n",
    "- JAX forces[<sup id=\"fn2-back\">2</sup>](#fn2) you to write _array-oriented_ code\n",
    "\n",
    "\n",
    "![image](https://raw.githubusercontent.com/jpivarski-talks/2023-12-18-hsf-india-tutorial-bhubaneswar/refs/heads/main/img/slow-fast-imperative-vectorized.svg)\n",
    "\n",
    "\n",
    "\n",
    "[<sup id=\"fn1\">1</sup>](#fn1-back) <sup>Can be written array-oriented with `nb.vectorize`.</sup> \n",
    "\n",
    "[<sup id=\"fn2\">2</sup>](#fn2-back) <sup>Can be written imperative with JAX's own loop primitives, e.g. `jax.lax.scan`.</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db9ef0f",
   "metadata": {},
   "source": [
    "### Limitations of Numba\n",
    "\n",
    "You can not JIT-compile arbitrary Python functions. Numba can only JIT-compile a subset of Python, i.e. everything that's \"known\" to Numba as a type (mostly NumPy & NumPy operations).\n",
    "\n",
    "For more information, see: https://numba.readthedocs.io/en/stable/user/5minguide.html#will-numba-work-for-my-code.\n",
    "\n",
    "\n",
    "Check the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b32f5665",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypingError",
     "evalue": "Failed in nopython mode pipeline (step: nopython frontend)\nnon-precise type pyobject\nDuring: typing of argument at /var/folders/34/_lhgt3t51_d5yqwccswc8k9w0000gn/T/ipykernel_23296/463706393.py (1)\n\nFile \"../../../../../../var/folders/34/_lhgt3t51_d5yqwccswc8k9w0000gn/T/ipykernel_23296/463706393.py\", line 1:\n<source missing, REPL/exec in use?>\n\nDuring: Pass nopython_type_inference \n\nThis error may have been caused by the following argument(s):\n- argument 0: Cannot determine Numba type of <class 'dict'>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypingError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m         out += v\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43msum_dict_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43ma\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3.0\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Fails, because `dict` is not a known type for Numba\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/repos/2025-07-07-scipy2025-tutorial-thinking-in-arrays/.pixi/envs/default/lib/python3.13/site-packages/numba/core/dispatcher.py:424\u001b[39m, in \u001b[36m_DispatcherBase._compile_for_args\u001b[39m\u001b[34m(self, *args, **kws)\u001b[39m\n\u001b[32m    420\u001b[39m         msg = (\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e).rstrip()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mThis error may have been caused \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    421\u001b[39m                \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mby the following argument(s):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00margs_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    422\u001b[39m         e.patch_message(msg)\n\u001b[32m--> \u001b[39m\u001b[32m424\u001b[39m     \u001b[43merror_rewrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtyping\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m errors.UnsupportedError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    426\u001b[39m     \u001b[38;5;66;03m# Something unsupported is present in the user code, add help info\u001b[39;00m\n\u001b[32m    427\u001b[39m     error_rewrite(e, \u001b[33m'\u001b[39m\u001b[33munsupported_error\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/repos/2025-07-07-scipy2025-tutorial-thinking-in-arrays/.pixi/envs/default/lib/python3.13/site-packages/numba/core/dispatcher.py:365\u001b[39m, in \u001b[36m_DispatcherBase._compile_for_args.<locals>.error_rewrite\u001b[39m\u001b[34m(e, issue_type)\u001b[39m\n\u001b[32m    363\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m365\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[31mTypingError\u001b[39m: Failed in nopython mode pipeline (step: nopython frontend)\nnon-precise type pyobject\nDuring: typing of argument at /var/folders/34/_lhgt3t51_d5yqwccswc8k9w0000gn/T/ipykernel_23296/463706393.py (1)\n\nFile \"../../../../../../var/folders/34/_lhgt3t51_d5yqwccswc8k9w0000gn/T/ipykernel_23296/463706393.py\", line 1:\n<source missing, REPL/exec in use?>\n\nDuring: Pass nopython_type_inference \n\nThis error may have been caused by the following argument(s):\n- argument 0: Cannot determine Numba type of <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "@nb.njit\n",
    "def sum_dict_values(d):\n",
    "    out = 0.\n",
    "    for v in d.values():\n",
    "        out += v\n",
    "    return out\n",
    "\n",
    "sum_dict_values({\"a\": 1.0, \"b\": 2.0, \"c\": 3.0})  # Fails, because `dict` is not a known type for Numba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802ff828",
   "metadata": {},
   "source": [
    "### Limitations of JAX\n",
    "\n",
    "JAX infers the operations that are going to be run through a \"tracing step\". Essentially, JAX will run your program once with shallow array objects (no data, just metadata). That let's you JIT-compile all of Python, **but** you can't JIT-compile data-dependent operations.\n",
    "\n",
    "For more \"sharp bits\", see: https://docs.jax.dev/en/latest/notebooks/Common_Gotchas_in_JAX.html.\n",
    "\n",
    "Check the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d9a169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traced<ShapedArray(float64[5])>with<DynamicJaxprTrace>\n"
     ]
    },
    {
     "ename": "TracerBoolConversionError",
     "evalue": "Attempted boolean conversion of traced array with shape bool[].\nThe error occurred while tracing the function sum_if at /var/folders/34/_lhgt3t51_d5yqwccswc8k9w0000gn/T/ipykernel_18396/583950977.py:3 for jit. This concrete value was not available in Python because it depends on the value of the argument arr.\nSee https://docs.jax.dev/en/latest/errors.html#jax.errors.TracerBoolConversionError",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTracerBoolConversionError\u001b[39m                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[99]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      9\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m jnp.prod(arr)\n\u001b[32m     12\u001b[39m array = jnp.array([\u001b[32m1.\u001b[39m, \u001b[32m2.\u001b[39m, \u001b[32m3.\u001b[39m, \u001b[32m4.\u001b[39m, \u001b[32m5.\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43msum_if\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# Fails, because jnp.any(arr > 3) is not traceable!\u001b[39;00m\n",
      "    \u001b[31m[... skipping hidden 14 frame]\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[99]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36msum_if\u001b[39m\u001b[34m(arr)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;129m@jax\u001b[39m.jit\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msum_if\u001b[39m(arr):\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mprint\u001b[39m(arr)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m jnp.any(arr > \u001b[32m3\u001b[39m):\n\u001b[32m      7\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m jnp.sum(arr)\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/repos/2025-07-07-scipy2025-tutorial-thinking-in-arrays/.pixi/envs/default/lib/python3.13/site-packages/jax/_src/core.py:1587\u001b[39m, in \u001b[36mconcretization_function_error.<locals>.error\u001b[39m\u001b[34m(self, arg)\u001b[39m\n\u001b[32m   1586\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34merror\u001b[39m(\u001b[38;5;28mself\u001b[39m, arg):\n\u001b[32m-> \u001b[39m\u001b[32m1587\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m TracerBoolConversionError(arg)\n",
      "\u001b[31mTracerBoolConversionError\u001b[39m: Attempted boolean conversion of traced array with shape bool[].\nThe error occurred while tracing the function sum_if at /var/folders/34/_lhgt3t51_d5yqwccswc8k9w0000gn/T/ipykernel_18396/583950977.py:3 for jit. This concrete value was not available in Python because it depends on the value of the argument arr.\nSee https://docs.jax.dev/en/latest/errors.html#jax.errors.TracerBoolConversionError"
     ]
    }
   ],
   "source": [
    "# Data-dependent operations are not traceable\n",
    "\n",
    "@jax.jit\n",
    "def accumulate_if(arr):\n",
    "    print(arr)\n",
    "    if jnp.any(arr > 3):\n",
    "        return jnp.sum(arr)\n",
    "    else:\n",
    "        return jnp.prod(arr)\n",
    "\n",
    "\n",
    "array = jnp.array([1., 2., 3., 4., 5.])\n",
    "print(accumulate_if(array))  # Fails, because jnp.any(arr > 3) is not traceable!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be44fdc",
   "metadata": {},
   "source": [
    "Another limitation of JAX is that you can't JIT compile programs with unknown shapes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4cac8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NonConcreteBooleanIndexError",
     "evalue": "Array boolean indices must be concrete; got ShapedArray(bool[5])\n\nSee https://docs.jax.dev/en/latest/errors.html#jax.errors.NonConcreteBooleanIndexError",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNonConcreteBooleanIndexError\u001b[39m              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[110]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m jnp.sum(arr[arr > \u001b[32m3.0\u001b[39m])\n\u001b[32m      6\u001b[39m array = jnp.array([\u001b[32m1.\u001b[39m, \u001b[32m2.\u001b[39m, \u001b[32m3.\u001b[39m, \u001b[32m4.\u001b[39m, \u001b[32m5.\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43msum_greater_than_three\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# Fails, because the output shape of `arr[arr > 3.0]` is not inferrable through tracing (without data)\u001b[39;00m\n",
      "    \u001b[31m[... skipping hidden 14 frame]\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[110]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36msum_greater_than_three\u001b[39m\u001b[34m(arr)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;129m@jax\u001b[39m.jit\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msum_greater_than_three\u001b[39m(arr):\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m jnp.sum(\u001b[43marr\u001b[49m\u001b[43m[\u001b[49m\u001b[43marr\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3.0\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/repos/2025-07-07-scipy2025-tutorial-thinking-in-arrays/.pixi/envs/default/lib/python3.13/site-packages/jax/_src/numpy/array_methods.py:1060\u001b[39m, in \u001b[36m_forward_operator_to_aval.<locals>.op\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1059\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mop\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args):\n\u001b[32m-> \u001b[39m\u001b[32m1060\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/repos/2025-07-07-scipy2025-tutorial-thinking-in-arrays/.pixi/envs/default/lib/python3.13/site-packages/jax/_src/numpy/array_methods.py:652\u001b[39m, in \u001b[36m_getitem\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m    651\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_getitem\u001b[39m(\u001b[38;5;28mself\u001b[39m, item):\n\u001b[32m--> \u001b[39m\u001b[32m652\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mindexing\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrewriting_take\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/repos/2025-07-07-scipy2025-tutorial-thinking-in-arrays/.pixi/envs/default/lib/python3.13/site-packages/jax/_src/numpy/indexing.py:639\u001b[39m, in \u001b[36mrewriting_take\u001b[39m\u001b[34m(arr, idx, indices_are_sorted, unique_indices, mode, fill_value, out_sharding)\u001b[39m\n\u001b[32m    633\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(aval, core.DShapedArray) \u001b[38;5;129;01mand\u001b[39;00m aval.shape == () \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    634\u001b[39m         dtypes.issubdtype(aval.dtype, np.integer) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    635\u001b[39m         \u001b[38;5;129;01mnot\u001b[39;00m dtypes.issubdtype(aval.dtype, dtypes.bool_) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    636\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(arr.shape[\u001b[32m0\u001b[39m], \u001b[38;5;28mint\u001b[39m)):\n\u001b[32m    637\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m lax.dynamic_index_in_dim(arr, idx, keepdims=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m639\u001b[39m treedef, static_idx, dynamic_idx = \u001b[43msplit_index_for_jit\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    640\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _gather(arr, treedef, static_idx, dynamic_idx, indices_are_sorted,\n\u001b[32m    641\u001b[39m                unique_indices, mode, fill_value, out_sharding)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/repos/2025-07-07-scipy2025-tutorial-thinking-in-arrays/.pixi/envs/default/lib/python3.13/site-packages/jax/_src/numpy/indexing.py:732\u001b[39m, in \u001b[36msplit_index_for_jit\u001b[39m\u001b[34m(idx, shape)\u001b[39m\n\u001b[32m    728\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mJAX does not support string indexing; got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m=}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    730\u001b[39m \u001b[38;5;66;03m# Expand any (concrete) boolean indices. We can then use advanced integer\u001b[39;00m\n\u001b[32m    731\u001b[39m \u001b[38;5;66;03m# indexing logic to handle them.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m idx = \u001b[43m_expand_bool_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m leaves, treedef = tree_flatten(idx)\n\u001b[32m    735\u001b[39m dynamic = [\u001b[38;5;28;01mNone\u001b[39;00m] * \u001b[38;5;28mlen\u001b[39m(leaves)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/repos/2025-07-07-scipy2025-tutorial-thinking-in-arrays/.pixi/envs/default/lib/python3.13/site-packages/jax/_src/numpy/indexing.py:1053\u001b[39m, in \u001b[36m_expand_bool_indices\u001b[39m\u001b[34m(idx, shape)\u001b[39m\n\u001b[32m   1049\u001b[39m   abstract_i = core.get_aval(i)\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m core.is_concrete(i):\n\u001b[32m   1052\u001b[39m   \u001b[38;5;66;03m# TODO(mattjj): improve this error by tracking _why_ the indices are not concrete\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1053\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m errors.NonConcreteBooleanIndexError(abstract_i)\n\u001b[32m   1054\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m np.ndim(i) == \u001b[32m0\u001b[39m:\n\u001b[32m   1055\u001b[39m   out.append(\u001b[38;5;28mbool\u001b[39m(i))\n",
      "\u001b[31mNonConcreteBooleanIndexError\u001b[39m: Array boolean indices must be concrete; got ShapedArray(bool[5])\n\nSee https://docs.jax.dev/en/latest/errors.html#jax.errors.NonConcreteBooleanIndexError"
     ]
    }
   ],
   "source": [
    "@jax.jit\n",
    "def sum_greater_than_three(arr):\n",
    "    return jnp.sum(arr[arr > 3.0])\n",
    "\n",
    "\n",
    "array = jnp.array([1., 2., 3., 4., 5.])\n",
    "print(sum_greater_than_three(array))  # Fails, because the output shape of `arr[arr > 3.0]` is not inferrable through tracing (without data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aec1619",
   "metadata": {},
   "source": [
    "### Impure functions are dangerous with JIT compilation! (Numba & JAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2d80a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accumulate with `np.prod`: 120.0\n",
      "Accumulate with `np.sum`: 120.0 ...Hey, this should've been 15.0 instead!\n"
     ]
    }
   ],
   "source": [
    "do_sum = False\n",
    "\n",
    "@nb.njit\n",
    "def accumulate(arr):\n",
    "    if do_sum:\n",
    "        return np.sum(arr)\n",
    "    else:\n",
    "        return np.prod(arr)\n",
    "\n",
    "\n",
    "array = np.array([1., 2., 3., 4., 5.])\n",
    "print(\"Accumulate with `np.prod`:\", accumulate(array))\n",
    "\n",
    "# now we switch `do_sum` on!\n",
    "do_sum = True\n",
    "print(\"Accumulate with `np.sum`:\", accumulate(array), f\"...Hey, this should've been {np.sum(array)} instead!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9718f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accumulate with `jnp.prod`: 120.0\n",
      "Accumulate with `jnp.sum`: 120.0 ...Hey, this should've been 15.0 instead!\n"
     ]
    }
   ],
   "source": [
    "do_sum = False\n",
    "\n",
    "@jax.jit\n",
    "def accumulate(arr):\n",
    "    if do_sum:\n",
    "        return jnp.sum(arr)\n",
    "    else:\n",
    "        return jnp.prod(arr)\n",
    "\n",
    "\n",
    "array = jnp.array([1., 2., 3., 4., 5.])\n",
    "\n",
    "print(\"Accumulate with `jnp.prod`:\", accumulate(array))\n",
    "\n",
    "# now we switch `do_sum` on!\n",
    "do_sum = True\n",
    "print(\"Accumulate with `jnp.sum`:\", accumulate(array), f\"...Hey, this should've been {jnp.sum(array)} instead!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee86c88",
   "metadata": {},
   "source": [
    "We can see why in the JAX case: that's because the traced program _never knew_ that there's a `sum` operation in the first place _and_ the compiled function is cached based on their input arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d6bb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traced program:\n",
      " { lambda ; a:f64[5]. let b:f64[] = reduce_prod[axes=(0,)] a in (b,) }\n",
      "\n",
      "HLO program:\n",
      " module @jit_accumulate attributes {mhlo.num_partitions = 1 : i32, mhlo.num_replicas = 1 : i32} {\n",
      "  func.func public @main(%arg0: tensor<5xf64>) -> (tensor<f64> {jax.result_info = \"result\"}) {\n",
      "    %cst = stablehlo.constant dense<1.000000e+00> : tensor<f64>\n",
      "    %0 = stablehlo.reduce(%arg0 init: %cst) applies stablehlo.multiply across dimensions = [0] : (tensor<5xf64>, tensor<f64>) -> tensor<f64>\n",
      "    return %0 : tensor<f64>\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Traced program:\\n\", accumulate.trace(array).jaxpr)\n",
    "print()\n",
    "print(\"HLO program:\\n\", accumulate.lower(array).as_text()) # this is the program that get's compiled by XLA compiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959cd834",
   "metadata": {},
   "source": [
    "### JIT-compilation for GPUs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19afa1a0",
   "metadata": {},
   "source": [
    "\n",
    "#### Numba.cuda\n",
    "\n",
    "Numba exposes CUDA to Python through the `numba.cuda` module. Here, the programming model follows very closely the CUDA C language by NVidia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b1d989",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "\n",
    "@cuda.jit\n",
    "def matmul(A, B, C):\n",
    "    \"\"\"\n",
    "    Perform square matrix multiplication of C = A * B\n",
    "    \"\"\"\n",
    "    i, j = cuda.grid(2)\n",
    "    if i < C.shape[0] and j < C.shape[1]:\n",
    "        tmp = 0.\n",
    "        for k in range(A.shape[1]):\n",
    "            tmp += A[i, k] * B[k, j]\n",
    "        C[i, j] = tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3f5595",
   "metadata": {},
   "source": [
    "#### JAX on GPUs\n",
    "\n",
    "JAX can run on GPUs without any code modifications (the power of array-oriented programming). The _symbolic_ operations of the IR (JaxPr) will just dispatch to GPU kernels instead of CPU kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8137a910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available devices: [CpuDevice(id=0)]\n",
      "array=Array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int64) lives on TFRT_CPU_0\n"
     ]
    }
   ],
   "source": [
    "# this runs on CPU and GPU, depending on the available `jax.devices()`\n",
    "\n",
    "@jax.jit\n",
    "def matmul(A, B): # -> C\n",
    "    \"\"\"\n",
    "    Perform square matrix multiplication of C = A * B\n",
    "    \"\"\"\n",
    "    return A @ B\n",
    "\n",
    "\n",
    "print(\"Available devices:\", jax.devices())\n",
    "\n",
    "# explicitely move data to devic (CPU or GPU):\n",
    "array = jax.device_put(jnp.arange(10), device=jax.devices()[0])\n",
    "\n",
    "print(f\"{array=} lives on\", array.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd8a09f",
   "metadata": {},
   "source": [
    "On to the [project.ipynb](project.ipynb)!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
